\documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}

\usepackage{cite}

\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
   \graphicspath{{figures/pdf/}{figures/png/}}
\else
   \usepackage[dvips]{graphicx}
   \graphicspath{{figures/eps/}}
\fi

\usepackage{multirow}
\usepackage{amssymb,amsmath,amsthm}
%\usepackage[lined,linesnumbered,boxed]{algorithm2e}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\usepackage{url}
% correct bad hyphenation here
\hyphenation{op-tical net-works}
%\hyphenation{op-tical net-works semi-conduc-tor}

\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax

\usepackage{hyperref}
\usepackage[ruled,vlined]{algorithm2e}

\begin{document}

\newcommand{\bm}[1]{\mbox{\boldmath{$#1$}}}
%%%\title{Anisotropic Quasi-harmonic Field for Feature Classification}
\title{Anisotropic Elliptic PDEs for Feature Classification}
\author{Shengfa~Wang,
         Tingbo~Hou ~\IEEEmembership{Student~Member,~IEEE,} Shuai~Li,
         Zhixun~Su, and~Hong~Qin,~\IEEEmembership{Senior~Member,~IEEE}
%\author{Shengfa~Wang, Tingbo~Hou, Shuai~Li, Zhixun~Su, and~Hong~Qin, Senior Member, IEEE%,~\IEEEmembership{Senior~Member,~IEEE}
        % <-this % stops a space
\IEEEcompsocitemizethanks{
\IEEEcompsocthanksitem
S. Wang, T. Hou, S. Li, and H. Qin are with the Department of Computer
Science, Stony Brook University (SUNY at Stony Brook),
\protect\\E-mail: shengfawang@gmail.com
\IEEEcompsocthanksitem
Z. Su is with the School of Mathematic Science, Dalian University of Technology.
}
}

%\thanks{Manuscript received April 19, 2005; revised January 11, 2007.}}

%The paper headers
\markboth{Transactions on Visualization and Computer Graphics,~Vol.~V, No.~N, March~2012}%
{Wang \MakeLowercase{\textit{et al.}}: Anisotropic Elliptic PDEs for Feature Classification}

\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
%\boldmath

The extraction and classification of multi-type (point, curve, patch)
features on manifolds are extremely challenging due to the lack of
rigorous definition for diverse feature forms. This paper seeks a
novel solution of multi-type features in a mathematically rigorous way
and proposes an efficient method for feature classification on
manifolds. We tackle this challenge by exploring a quasi-harmonic
field (QHF) generated by elliptic PDEs, which is the stable state of
heat diffusion governed by anisotropic diffusion tensor. Diffusion
tensor locally encodes shape geometry, and controls velocity and
direction of the diffusion process. The global QHF weaves points into
smooth regions separated by ridges, and has superior performance in
combating noise/holes. Our method's originality is highlighted by the
integration of locally-defined diffusion tensor and globally-defined
elliptic PDEs in an anisotropic manner. At the computational front,
the heat diffusion PDE becomes a linear system with Dirichlet
condition at heat sources (called seeds). Our new algorithms afford
automatic seed selection, enhanced by a fast update procedure in a
high dimensional space. By employing diffusion probability, our method
can handle both manufactured parts and organic objects. Various
experiments demonstrate the flexibility and high performance of our
method.
%
%The extraction and classification of multi-type (point, curve, patch,
%etc.) features on manifolds are extremely challenging due to the lack
%of rigorous definition for diverse feature forms. In this paper, we
%seek a novel technical solution of multi-type features in a
%mathematically rigorous way and propose an efficient method for
%feature extraction and classification on curved surfaces. We tackle
%this challenge by exploring a quasi-harmonic field (QHF) generated by
%elliptic PDEs, which can be considered as the stable state of heat
%diffusion governed by anisotropic diffusion tensor. At the local
%scale, diffusion tensor intrinsically encodes shape geometry, and
%controls velocity and direction of the diffusion process. At the
%global scale, the QHF naturally weaves points into smooth regions
%separated by ridges, and it has superior performance in
%combating noise and holes. Our method's originality is highlighted by
%the elegant integration of locally-defined diffusion tensor and
%globally-defined elliptic PDEs in an anisotropic manner. At the
%computational front, the partial differential equation of heat
%diffusion becomes a linear system with Dirichlet condition at heat
%sources (also called seeds). Our new algorithms afford automatic seed
%selections, enhanced by a fast update procedure in a high dimensional
%space. By employing a new feature classification based on diffusion
%probability, our method can handle both rigid manufactured parts and
%organic deformable objects. Various experiments are conducted to
%demonstrate the ease of manipulation and high performance of our
%method.
\end{abstract}

% Note that keywords are not normally used for peer review papers.
\begin{keywords}
Diffusion tensor, Elliptic PDE, Quasi-harmonic field, Feature
classification.
\end{keywords}}

% make the title area
\maketitle

\IEEEdisplaynotcompsoctitleabstractindextext

\IEEEpeerreviewmaketitle

\begin{figure}
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{}}
\includegraphics[width=0.48\columnwidth,keepaspectratio]{fandisk_holes.eps}&
\includegraphics[width=0.45\columnwidth,keepaspectratio]{fandisk_noise_features.eps}\\
\includegraphics[width=0.19\textwidth,keepaspectratio]{boy_noise_weak_smooth_features_1.eps}&
\includegraphics[width=0.21\textwidth,keepaspectratio]{boy_holes.eps}\\
%\includegraphics[width=0.17\textwidth,keepaspectratio]{boy_noise_weak_smooth_features_2.eps}\\
\end{tabular}
\caption{Feature extraction and classification
on models with noise ($10\%$ random noise) and holes. Different patch
features are decorated in different colors, while curve and point
features are colored in red. The connected curve features of Fandisk
are highlighted as a wire-frame representation.}
\label{fig:illustrate}
\end{center}
\end{figure}

\section{Introduction}

\IEEEPARstart{F}{eature} extraction and classification have been
of great practical importance in many graphics tasks and applications,
with ever-increasing interest in recent years. Extensive studies on
feature extraction, while continuing for more than a decade, have been
gaining momentum because features can assist recognition, deformation,
parameterization, segmentation, shape analysis and understanding, and
many more~\cite{QY04,ZMT05,AS10}. Features can be classified into
multiple types that may include point feature, curve feature, patch
feature, etc. From the unified viewpoint of feature extraction and
model segmentation, the central task of feature classification is to
weave points into homologous features of different categories, whose
union collectively comprise the original shape. To aid downstream
graphics applications, the extraction and classification of multi-type
features must be of relevance to intrinsic geometry structure. The
fundamental goal of this paper is to advocate an integrated strategy
for feature identification, extraction, and clustering, and develop a
robust and efficient method to classify multi-type features of curved
geometry.

Local geometric attributes, such as curvature, normal, and other
surface measurements~\cite{MDSB02}, are frequently used to detect
features. They are simple and intuitive, but suffer from noisy
perturbation and incomplete information. As a local geometry
description, tensor voting theory has demonstrated great advantages in
modeling tasks such as feature detection, clustering and
recognition~\cite{GM00,PSKP*02,LDB05,KCL09}. The voting tensor is a
local attribute with rich information of local geometry, which can
explicitly determine the latent classification of a vertex by
analyzing its eigenvectors. It has advantages over commonly-used local
geometric attributes. Nevertheless, certain limitations still exist.
It is still sensitive to noise, resulting in degraded performance for
distinguishing weak features from noise. Due to the lack of knowledge
for global shape information, tensor voting alone falls short of
distinguishing different patch features.

Diffusion process, which is intrinsically related to the probability
of random walks~\cite{LHMR09,ZZC11}, is a powerful tool in tackling
many graphics problems. It elegantly bridges the large gap between
local and global behaviors via time scale, and has witnessed a great
accomplishment in the rapid development of heat diffusion algorithms
on manifolds~\cite{DMSB99,UUM00,SOG09,SMH10}. Recent works oftentimes
concentrate on dynamic solutions of the partial differential equation
of heat diffusion, which typically requires global eigenfunctions of
the Laplace-Beltrami operator and convolution with heat kernels, is
very time-consuming. However, when the diffusion arrives at its steady
state, time variable can be omitted in the notation, the diffusion
problem then reduces to an elliptic PDE that is a linear system
constrained by the heat sources. Moreover, most previous heat
diffusion processes are designed isotropically, based on isotropic
heat kernels on manifolds. For the problem of feature analysis,
directly using the diffusion process will naturally give rise to the
smooth transition between nearby regions, without having evident clues
on feature types and how they are weaved to dictate a globally
meaningful structure. To tackle this problem, an anisotropic diffusion
has the capability of controlling diffusion directions by assigning
weighted diffusion operators locally, and is much more favorable. In
addition, the steady state of the heat diffusion corresponds to a
quasi-harmonic field (QHF) generated by an elliptic PDE with the
weighted diffusion operators.

\begin{figure}
\begin{center}
\begin{tabular}{@{}c@{}}
\includegraphics[width=0.45\textwidth, keepaspectratio]{outflow.eps} \\
\end{tabular}
\caption{The functional pipeline of our new method.}
\label{fig:outflow}
\end{center}
\end{figure}

In this paper, we explore a multi-type feature classification based on
diffusion tensor weighted quasi-harmonic field, which collectively
inherit the advantages of local geometric tensors and global
diffusion. The local geometric tensor is a diffusion tensor used to
control a global anisotropic diffusion process on manifolds. Another
advantage of this approach is that it is tunable through a few
intuitive parameters and is stable under near-isometric deformations.
From the diffusion's point of view, a patch feature can be defined as
a collection of piecewise smooth regions weaved together by the
diffusion in a QHF. A curve feature is a curve where the QHF exhibits
certain types of discontinuity, and we may consider a sharp edge as a
good example of curve features. A point feature is an isolated point
scattered in isolation across the QHF. A transition feature can be
viewed as a region that is littered on manifolds dominated by the
above features. Fig.~\ref{fig:illustrate} highlights multi-type
features extracted from models with noise and holes. The weak features
and smooth transition features can also be detected.
Fig.~\ref{fig:outflow} illustrates the pipeline of our approach.
First, we transform the normal voting tensor to diffusion tensor, and
then use it to initially assign feature types for vertices. A high
dimensional QHF is computed according to the seeds that are enforced
as constraints in such space.  Note that our seeds are automatically
selected during the classification procedure, where user interaction
is also supported. Then, a diffusion probability based feature
classification is exploited to classify vertices into features of
different types, such as point features, curve features, and patch
features. Finally, the curve-tracking and post-processing procedures
are applied. Our approach can handle 2D manifold of arbitrary topology
effectively. The salient contributions of this paper include:
\begin{itemize}
\item
We formulate a versatile diffusion tensor, which can be used to
control the anisotropic diffusion, distinguish weak features from
noise, and guide curve-tracking, etc.

\item
We devise a probability metric based seed selection mechanism, which
automatically determines the position and the number of seeds
according to the shape information.

\item
We convert the diffusion problem to a linear system with boundary
value subject to the seed constraints, then a high dimensional
quasi-harmonic field is obtained by fast updating the Elliptic PDEs in
such space.

\item
We develop a classification algorithm based on diffusion probability,
which can be directly computed from the high dimensional
quasi-harmonic field.

\item
We propose a complete and robust framework for multi-type feature
extraction and classification that elegantly integrates the local
diffusion tensor and global diffusion, and it is tunable through a few
intuitive parameters and is stable under near-isometric deformations.

\end{itemize}

The remainder of this paper is organized as follows. We briefly review
related work in Section~\ref{sec:related_work}. We introduce the
theory and property of the diffusion tensor in Section~\ref{sec:DT}.
The theoretical foundation and algorithmic steps of the proposed
method are detailed in Section~\ref{sec:Ap}, including feature
initialization, quasi-harmonic field construction, fast update, and
feature classification. We demonstrate our experimental results from
various aspects and discuss current limitations of our method in
Section~\ref{sec:ERD}. Finally, we conclude our work in
Section~\ref{sec:CFW}.

%-------------------------------------------------------------------------
\section{Background Review}
\label{sec:related_work}

Feature detection and classification can be augmented by using the
knowledge from differential geometry~\cite{BAK97,KKM05}. To accurately
compute differential properties, both local estimation
techniques~\cite{SF04,CRT04,SAH05,RDo06} and global surface
fitting~\cite{KMWJ96,OBS04} are employed. The local estimation carries
out computation in neighboring triangles of a point for fast
computation. In general, the global surface fitting can enable the
calculation of high-order derivatives and curvature extrema more
accurately than local estimation. However, it is difficult for these
methods to recognize and classify different types of features. As a
viable solution, the tensor voting theory~\cite{GM00,MLT00} is
adopted. Sun et al.~\cite{PSKP*02} defined the normal voting tensor of
a vertex on a triangular mesh by considering the unit normal vectors
of neighboring triangles. This method can only recognize regions
bounded by high-curvature borders. Lavou\'e et al.~\cite{LDB05}
introduced a method that can detect weak features and smooth
transition features by using curvature tensor. Since the estimation of
curvature is sensitive to noisy and sampling artifacts, it tends to
over-cut the entire mesh into many small pieces. Kim et
al.~\cite{KCL09} developed an alternate method by adopting the tensor
voting theory, which can detect both sharp edges and transition
features. However, patch features are not clustered into meaningful
pieces. Besides, only local information is involved in this method,
resulting in unstableness to noisy input.  Wang et al.~\cite{whsq11_b}
overcome this problem using tensor-driven diffusion for feature
classification, however, the method can only handle rigid models.
Based on the characteristics of intersection curves with blowing
bubbles, Mortara et al.~\cite{MPGM*03} proposed a method to locally
classify vertices into a few types, which is different from our
approach that takes global shape of features into account. To extract
the global shape of features, ideas from mathematical morphology have
been extended to surfaces~\cite{RKSS00}. However, they did not further
classify the features and manipulate them corresponding to their
types. Later, Lai et al.~\cite{LZHW*07} proposed a feature region
extraction and classification method based on a remeshing algorithm
and feature sensitive metric, at the cost of topology changes. Sunkel
et al.~\cite{SJW*11} learned simply line features from the
user-specified input with training examples, but they could not find
complex features with cycles.

Clustering can also be interpreted as a part of feature
classification, which segments a shape to several patches. From the
feature's perspective, a clustering should partition a mesh into parts
characterized by similarity, with boundaries as salient curves. In
graphics applications, there is a large literature on clustering, such
as k-means~\cite{SA03,LZHM06,PDEK09}, region
growing~\cite{ODRD02,JLCW06,zheng2010}, spectral clustering~\cite{LZ04}, mean
shift~\cite{SYLL*05,CGF10}, random walks~\cite{LHMR09,ZZC11},
etc. Katz and Tal~\cite{SA03} adopted fuzzy clustering and minimal
boundary cut to obtain smoother boundaries between k-mean
clusters. Lai et al.~\cite{LZHM06} combined integral and statistical
quantities to segment meshes with noisy or repeated patterns. One of
the drawbacks of these algorithms is that they have to compute
pairwise distances, which is extremely time-consuming for large
meshes. Sorkine et al.~\cite{ODRD02} addressed mesh segmentation by
greedy region growing, while optimizing different criteria. The easy
mesh cutting algorithm~\cite{JLCW06} is introduced to cluster the
similar regions using region growing, which heavily relies on seed
positions and is therefore sensitive to noise. Spectral
clustering~\cite{LZ04} is also adopted for mesh segmentation. But the
clusters are not aware of features and their spatial
relationship. Yamauchi et al.~\cite{SYLL*05} employed mean shift
clustering of surface normals, for which computational complexity may
be a prominent difficulty. Xiao and Liu~\cite{CGF10} used K-D tree to
accelerate the algorithm. However, these methods tend to
over-aggressively segment a mesh into more pieces than what are
expected or desired. Lai et al. ~\cite{LHMR09} exploited random walks
to segment meshes by solving a linear system. However, since the
matrix of random walks is not symmetric, it does not admit fast
Cholesky factorization. Also, they did not consider weak
features. Constrained random walk~\cite{ZZC11} is developed to
achieve smooth cutting contours. However, the cutting only occurs
between two clusters. We refer readers to the excellent survey
papers~\cite{CGF08,HJGM10} for the comprehensive references and
comparison on the topic of clustering.

%-------------------------------------------------------------------------
\section{Anisotropic Diffusion Tensor}
\label{sec:DT}

In this section, we introduce an anisotropic diffusion tensor that
controls both the velocity and the direction of a global diffusion. It
is derived from the normal voting tensor, but has a different
formulation with more discriminative power enabled by the anisotropic
diffusion. We further explore its versatile capacity to detect weak
features, resist noise, and guide post-treatment procedure.

A normal voting tensor $\textbf{NT}(v_i)$ of a vertex $v_i$ can be
computed by the sum of the weighted covariance
matrices~\cite{GM00,PSKP*02,KCL09},
\begin{equation}\label{eq:NVT}
\textbf{NT}(v_i) = \sum_{t_j\in{N_t(v_i)}}\mu_j \textbf{n}_{t_j}\textbf{n}_{t_j}^T,
\end{equation}
where $t_j$ is a triangle, $N_t(v_i)$ denotes the set of neighboring
triangles of $v_i$, $\textbf{n}_{t_j}$ is the normal of triangle
$t_j$, and $\mu_j$ is the weight coefficient (set as 1 in our work).

Since the normal voting tensor is a positive semi-definite tensor with
second order, it can be diagonalized by eigenvalues
($\lambda_1>\lambda_2>\lambda_3\geq 0$) and reformulated by a spectral
representation
\begin{equation}\label{eq:NVT_}
\textbf{NT}(v_i) = \lambda_1 \textbf{e}_1 \textbf{e}^T_1 +\lambda_2 \textbf{e}_2 \textbf{e}^T_2 +\lambda_3 \textbf{e}_3 \textbf{e}^T_3 ,
\end{equation}
where $\textbf{e}_i$ is the corresponding eigenvector of $\lambda_i$,
$i=1,2,3$.

\begin{figure}
\begin{center}
\begin{tabular}{@{}c@{}}
\includegraphics[width=0.5\textwidth, keepaspectratio]{diffusion_tensor.eps} \\
\end{tabular}
\caption{The illustration of diffusion tensor and its propagation.
Left: The diffusion velocities at one vertex along all the directions
can be illustrated by an ellipsoid. Right: The principal diffusion
directions (denoted as red arrows) of three different vertices
(highlighted as small red balls) on a cube are shown. The dash lines
initiated from corner vertex represent the directions with the
diffusion velocities very close to zero. }
\label{fig:ellipsoid}
\end{center}
\end{figure}

The three eigenvectors of a normal voting tensor are orthogonal, and
the eigenvalues characterize the diffusion velocities along the
directions of the corresponding eigenvectors. Directly adopting the
normal voting tensor as the diffusion tensor will lead to fast
diffusion when crossing sharp edges, and slow diffusion when traveling
along them. This is, however, exactly opposite to our goal. Therefore,
we design a new diffusion tensor to assist the task of classifying
vertices subject to different types, given by
\begin{equation}\label{eq:DT}
\textbf{D}(v_i) =\widetilde{\lambda}_1 \textbf{e}_1 \textbf{e}^T_1 +\widetilde{\lambda}_2 \textbf{e}_2 \textbf{e}^T_2 +\widetilde{\lambda}_3 \textbf{e}_3 \textbf{e}^T_3 ,
\end{equation}
where
\begin{equation}\label{eq:lambda}
\widetilde{\lambda}_i= \exp\Big(-\frac{\lambda_i}{\delta_D}\Big) , i=1,2,3,
\end{equation}
with diffusion parameter $\delta_D$ that controls diffusion
velocities. The smaller $\delta_D$ is, the harder heat diffuses
through the hindrance, such as sharp edge, and vice versa.
Intuitively speaking, we construct an ellipsoid at each vertex that
encodes the direction and velocity of diffusion, as illustrated in
Fig.~\ref{fig:ellipsoid}(left). According to the theory of Rayleigh
quotient~\cite{HJ85}, the diffusion velocity from the vertex $v_i$
along a vector $\textbf{e}$ can be expressed as
\begin{equation}\label{eq:DV}
vel(v_i,\textbf{e})=
\frac{\textbf{e}^T\textbf{D}(v_i)\textbf{e}}{{\textbf{e}}^T\textbf{e}}.
\end{equation}
It can be interpreted as the length of the vector projection onto the
ellipsoid.

Usually, the principal diffusion direction is the most informative
one, which is defined as the direction corresponding to the maximal
diffusion velocity. For a vertex on a plane, all the directions
embedded on the plane are its principal diffusion directions, since
all the diffusion velocities are equal. For a vertex on a sharp edge,
the direction along the edge is its principal diffusion direction. For
a vertex on a corner, all the directions are considered to be its
principal diffusion directions. However, the velocities along all the
directions are extremely small. Therefore, almost no heat can flow in
or out. Fig.~\ref{fig:ellipsoid}(right) shows the principal diffusion
directions and the propagation modes of the three types of vertices.
The principal diffusion directions are also used to distinguish weak
features from noise, and guide the feature curve growing and merging
process.

%-------------------------------------------------------------------------
\section{Our Novel Method}
\label{sec:Ap}

Given a triangular mesh, our method classifies all the vertices into
features with different types. Our new method is founded upon the
computation of anisotropic elliptic PDEs subject to Dirichlet boundary
conditions. It comprises four steps: initial feature analysis,
numerical construction of the anisotropic elliptic PDEs, feature
classification, and curve-tracking and post-processing.

\begin{algorithm}[t]
\SetLine
Parameters: $c_f=0.03$, $c_c=0.1$, $c_s=0.3$.\\
\For{each vertex}{
\uIf{$\lambda_3>c_c$}{
mark corner vertex\;}
\uElseIf{$\lambda_2<c_f$}{
mark planar vertex\;}
\uElseIf{$\lambda_2>c_s$ $\&$ $\lambda_3<c_c$ $\&$ NVC}{
mark sharp vertex\;}
\uElseIf{$c_f\leq \lambda_2\leq c_s$ $\&$ $\lambda_3<c_c$ $\&$ NVC}{
mark weak vertex\;}
\Else{mark noisy vertex\;}
}
\caption{Feature Initialization.}
\label{initialization}
\end{algorithm}

\subsection{Feature Initialization}
\label{sec:IFA}

An initial type is assigned to each vertex according to the principal
diffusion directions and the eigenvalues of its structure tensor. This
initial assignment conducts a general classification of vertices, and
extracts vertices with salient characteristics, such as corners and
sharp edges. The rest will be further classified in subsequent steps.

According to the eigen-analysis and the neighboring relationship, we
assign vertices to different initial types: planar vertices, corner
vertices, sharp vertices, weak vertices, and noisy vertices. Compared
with the method in~\cite{KCL09}, our method has the ability to
distinguish weak vertices from noise. Since the relative difference
between eigenvalues is crucial for classifying vertices, the
eigenvalues are normalized to bring consistency into different data
using
\begin{equation}\label{eq:normalize}
\frac{\lambda_i}{\sqrt{\lambda^2_1+\lambda^2_2+\lambda^2_3}}, i=1,2,3.
\end{equation}
For convenience, all the eigenvalues mentioned later are normalized,
and we still denote them as $\lambda_i$.

\begin{figure}
\begin{center}
\begin{tabular}{@{}c@{}}
\includegraphics[width=0.3\textwidth, keepaspectratio]{NVC.eps}\\
\end{tabular}
\caption{The weak features (blue dots) and the noisy vertices
(orange dots) can be clearly separated via the NVC criterion.
The arrows are the corresponding principal diffusion directions
and the red line is the weak feature line.}
\label{fig:NVC}
\end{center}
\end{figure}

The types of planar vertices, corner vertices, and sharp vertices can be directly determined
by the corresponding eigenvalues due to the tremendous
differences. To discriminate weak
vertices and noisy vertices, we design a criterion, named
\emph{neighboring vertex coincidence} (NVC), by considering more
neighbors. It utilizes the fact that a feature vertex often has
neighboring vertices with similar characteristics, while a noisy
vertex and its neighboring vertices usually have different principal
diffusion directions. Given a vertex $v_i$ not belonging to planar
vertices, we say the vertex conforms to the NVC criterion, if it
satisfies either of the following two conditions: 1) We put $v_i$ into
a front propagation set. Along its principal diffusion direction,
there are non-planar vertices having similar principal diffusion
directions (with intersecting angles less than $15^\circ$) in its
neighbors. If such coincident vertex exists and is not a corner
vertex, we mark it as the new front and keep this front tracking
procedure going. The number of found coincident vertices is greater
than 2.  2) There are two non-planar neighbor vertices having similar
principal diffusion directions, which are also coincident with the
corresponding edge that connects $v_i$ and the neighbor vertex.
Fig.~\ref{fig:NVC} shows an example of using the NVC criterion to
distinguish the weak features from noise. The algorithm of initial
feature assignment is documented in Algorithm~\ref{initialization}.
The parameter $c_f$ controls the boundary interface separating planar
vertices and other ones, which has a large influence on curve
features, and we call it the curve feature parameter and will further
discuss it in the result section.  The parameter $c_c$ and $c_s$
controls the selection of corner vertices and sharp vertices
respectively, and they have little influence on the classification
results and are determined empirically.  However, a proper parameteter
setup can increase efficiency, this is because once the sharp vertices
are determined, they no longer need further processing. Moreover,
since the eigenvalues are normalized, the parameters in the algorithm
are consistent for different models.


Since we do not categorize noise as a feature type, a separate process
is taken to re-assign feature types for weak vertices and noisy
vertices. Considering that the diffusion is a global PDE that has a
built-in resistance to noise, a simple smoothing and enhancement
procedure suffices for this purpose. We process a noisy vertex by
smoothing the second eigenvalue of the voting tensor according to its
neighbors, given by
\begin{equation}\label{eq:enhancement_1}
\lambda_2(v_i) = \frac{\sum_{j\in N(i)} vel(v_j,v_i-v_j)\lambda_2(v_j)}{\sum_{j\in \widetilde{N}(i)} vel(v_j,v_i-v_j)},
\end{equation}
where $\lambda_2(v_i)$ is the second eigenvalue of the voting tensor
of $v_i$. Then, we enhance the weak vertices by simply enlarging
the second eigenvalue of the voting tensor by a factor of 10.  If a
weak vertex satisfies only the second condition of NVC, we need
to further replace its diffusion tensor by the average diffusion
tensors of the coincident neighbors.  After this procedure, noisy
vertices are further classified into weak vertices or planar
vertices, while weak vertices are enhanced and re-classified into
the sharp vertices. After the initial feature assignment, we
mark corner vertices as point features, and the sharp vertices
as curve features. From the global point of view, the boundary of a
patch feature can also be treated as global curve features. The planar
vertices will be further classified into different patch features and
curve features.

\subsection{Quasi-harmonic Fields}
\label{sec:WHF}

In our method, we utilize the QHF to provide the stable distribution
of heat with some heat sources (seeds), which are Dirichlet conditions
for elliptic PDEs. The heat diffusion over a manifold $M$ is
governed by the heat equation. We formulate the weighted diffusion
process as
\begin{equation}\label{eq:diffusion}
\begin{cases}
\frac{\partial u(v,t)}{\partial t}=-div(\widetilde{\textbf{D}} \nabla u(v,t)) & t \in R^{+}\\
u(v,t)=c(v) & v \in S\\ u(v,0)=0 & \mbox{$v \in$ others}
\end{cases}
\end{equation}
where the diffusivity $\widetilde{\textbf{D}}$ is a $3\times3$
symmetric matrix, $S$ is a set of seeds, and $c(v)$ is the fixed value
of seed $v$. The weight matrix $\widetilde{\textbf{D}}$ serves for two
purposes: encoding diffusion tensor $\textbf{D}$, and characterizing
geometric difference between neighboring vertices. These local
attributes are crucial for our feature classification, which will be
addressed next.

\begin{figure}
\begin{center}
\begin{tabular}{@{}c@{}}
\includegraphics[width=0.5\textwidth, keepaspectratio]{QHF.eps} \\
\end{tabular}
\caption{The QHFs generated using common cotangent Laplace operator
(left) and our anisotropic diffusion operator (right). The seeds are
cold source with the constant temperature of 0 and hot source with the
constant temperature of 1, respectively.}
\label{fig:QHF}
\end{center}
\end{figure}

From a global perspective, we allow heat diffusion to reach its
equilibrium and consider the stable state of the weighted diffusion in
Eq.~(\ref{eq:diffusion}). When the diffusion has reached its stable
state, time $t$ is omitted in the notation. Then,
Eq.~(\ref{eq:diffusion}) reduces to an elliptic PDE
\begin{equation}\label{eq:Laplace}
\begin{cases}
div(\widetilde{\textbf{D}} \nabla u(v))=0\\
u(v)=c(v) & v\in S
\end{cases}
\end{equation}
whose solution is a QHF. The discrete formulation of
Eq.~(\ref{eq:Laplace}) can be written into matrix form
\begin{equation}\label{eq:Linear}
\textbf{L}\textbf{F}=0,
\end{equation}
subject to Dirichlet conditions $\textbf{F}(v)=c(v), v \in S$, where
$\textbf{L}$ is a $n\times n$ coefficient matrix, and $\textbf{F}$ is
a quasi-harmonic field. The coefficient matrix $\textbf{L}$ has
elements
\begin{equation}
\begin{cases}
\textbf{L}_{ij}=-K(v_i,v_j),\\
\textbf{L}_{ii}=\sum_{j\in {N(i)}}K(v_i,v_j),
\end{cases}
\end{equation}
with
\begin{equation}\label{eq:K}
K(v_i,v_j)=\exp\Big(-\frac{(v_i-v_j)^T \textbf{D}(v_i,v_j)^{-1}(v_i-v_j)}{{\delta}_K}\Big),
\end{equation}
where $\textbf{D}(v_i,v_j)=w_{ij}(\textbf{D}(v_i)+\textbf{D}(v_j))$,
and $\delta_K$ is a penalty factor set to be the inverse of the
maximal eigenvalue of diffusion tensors $\textbf{D}(v_i)$ and
$\textbf{D}(v_j)$. The geometry-aware weight $w_{ij}$ is used as a
diffusion tensor aide, and it is defined as
\begin{equation}\label{eq:weight}
w_{ij}=\exp\Big(-\frac{\|\textbf{NCC}_i-\textbf{NCC}_j\|}{\delta_{G}}\Big),
\end{equation}
where $\textbf{NCC}_i$ denotes normal-controlled coordinates
(NCC)~\cite{WHSQ11_a} of vertex $v_i$, and $\delta_{G}$ is a
geometry-dilation parameter that controls the influence of geometry
descriptor NCC. Here $\delta_{G}$ is set to be $\max \{avg_f(\mid
NCC\mid), 0.3\}$, where $avg_f(\mid NCC\mid)$ is the average value of
the NCCs of non-planar vertices. We use NCC here, because they encode
local geometric details of a vertex along its normal direction, and
have proper behaviors for open surfaces without tangential tension. In
this way, geometric differences of neighboring vertices are well
categorized. Since the diffusion tensor $\textbf{D}(\cdot)$ is
positive definite and $w_{ij}=w_{ji}$ is a positive constant, the
value of Eq.~(\ref{eq:K}) is within interval (0,1]. Moreover, it is
easy to have $K(v_i,v_j)=K(v_j,v_i)$, and we know that the coefficient
matrix $\textbf{L}$ is symmetric. Fig.~\ref{fig:QHF} shows an example
of our QHF with two seeds. Our QHF has shown a clear temperature
discrepancy between different parts separated by the sharp edge.

\subsection{Fast Update QHF in High Dimensional Space}

A QHF is the solution of an elliptic PDE~(\ref{eq:Linear}) with
Dirichlet conditions at seeds. A new seed will be automatically
selected according to the current QHF if the classification is
unfinished. For large meshes, it is time-consuming to solve the QHF
every time after the seeds are updated. We adopt the popular
\emph{Penalty method}~\cite{XZCX09} to fast update the QHF with
Dirichlet condition assigned by the seeds. Specifically, $\textbf{L}$
is symmetric which admits fast Cholesky factorization and fast
updating of Cholesky~\cite{DH06}. As a result, adding/removing
seed constraints can be written as matrix additions. On the other
hand, in order to adjust the quasi-harmonic field suitable for
clustering, we construct a high dimensional quasi-harmonic field in
$R^d$ using selected seeds, where $d$ is the number of seeds. Hence,
we need to put seeds in $R^d$ to construct high dimensional
constraints, which is a $n\times d$ matrix.  Each column of the
constraint matrix associates with one seed initially valued as 1, and
the other seeds are set to be 0. Now $\textbf{F}$ becomes a $n\times
d$ unknown matrix, which represents $d$-dimensional quasi-harmonic
fields. The region where the values are most similar to that of a seed
in the quasi-harmonic field is treated as a patch feature. Then,
Eq.~(\ref{eq:Linear}) can be rewritten as
\begin{equation}\label{eq:Penalty_function}
(\textbf{L} + \bar{\textbf{P}})\textbf{F} =
\bar{\textbf{P}}\textbf{B}, \\ \bar{\textbf{P}}=\textbf{P} +
\textbf{U}\textbf{U}^T - \textbf{R}\textbf{R}^T,
\end{equation}
where the $n\times n$ penalty matrix $\textbf{P}$, the $n\times n$
modification matrices $\textbf{U}$ and $\textbf{R}$, and the $n\times
d$ constraint matrix $\textbf{B}$ have the following entries:
\begin{displaymath}
\begin{aligned}
&\textbf{P}_{ij} = \begin{cases}
                         \alpha  & \hbox{$i=j\in C$}\\
                         0 & \hbox{otherwise} \\
                       \end{cases}
&&\textbf{U}_{ij} =\begin{cases}
                         \sqrt{\alpha}  & \hbox{$i=j\in C_{i}$}\\
                         0 & \hbox{otherwise} \\
                       \end{cases} \\
&\textbf{R}_{ij}=\begin{cases}
                            \sqrt{\alpha}  & \hbox{$i=j\in C_{d}$}\\
                         0 & \hbox{otherwise} \\
                       \end{cases}
&&\textbf{B}_{ij} =\begin{cases}
                         1  & \hbox{$i$ is the $j$th in $\bar{C}$ }\\
                         0 & \hbox{otherwise} \\
                       \end{cases}
 \end{aligned}
\end{displaymath}
with $\alpha$ being the penalty factor, $C$ the indices for the
previous seeds, $C_{i}$ the indices for newly-inserted seeds, $C_{d}$
the indices of seeds to be deleted, and $\bar{C}$ the indices for the
updated seeds. As for the penalty factor, we choose $\alpha=10^8$ for
all the examples in our current implementation. It may be noted that,
the penalty method only handles soft constraints, so the $\alpha$
value must be large enough to confine the values at seeds within a
proper range~\cite{XZCX09}.

%I add a reference here.

Our seed selection is different from the previous methods. We design a
probability distance based scheme to automatically select seeds in the
classification procedure. Given a quasi-harmonic field, we classify a
subset of planar vertices into patch features. Then, a new seed is
selected from the non-classified planar vertices. We can obtain the
updated quasi-harmonic field corresponding to the newly-updated
seeds. The process is repeated until all the planar vertices are
classified. We compute the initial quasi-harmonic field by randomly
selecting two seeds from the planar vertices with the Euclidean
distance larger than the radius of the model's bounding sphere. This
can avoid over-classification. Meanwhile, our system also supports
user interaction for seed selection, which can fulfill specific needs
of feature segmentation. The seed selection and feature classification
will be detailed in the following subsection.

\begin{figure}[t]
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{}}
\includegraphics[width=0.32\textwidth, keepaspectratio]{distance.eps}&
\includegraphics[width=0.045\textwidth, keepaspectratio]{bar.eps} \\
\end{tabular}
\caption{An example illustrates the automatic seed selection
mechanism. The color represents a distance field: the sum of
the probability distances from a vertex to all the
existing seeds (denoted as blue balls). The iso-lines are constructed
by connecting vertices. The new seed (denoted as a red ball) is
introduced at a location which has minimum value in the distance
field.}
\label{fig:distance}
\end{center}
\end{figure}

\subsection{Feature Classification based on Diffusion Probability}
\label{sec:FC}

We classify features by a self-adaptive algorithm based on the
newly-introduced concept of diffusion probability (DP). After the
$d$-dimensional QHF $F$ is computed from
Eq.~(\ref{eq:Penalty_function}), the DP of a vertex $v_i$ to the
$j$-th seed $DP(v_i,j)$ is intuitively defined as the $j$-th element
of $F_i$, where $F_i=(F_{i1},...F_{id})^T$ is the vector value of the
QHF at vertex $v_i$. According to our prior discussion on high
dimensional QHF and their valid value ranges, we observe that each
scalar component of this $d$-dimension vector at any vertex is a
non-negative value between $0$ and $1$, it is both natural and
mathematically intuitive to consider the $d$-dimensional vector field
at a vertex as a probability distribution function with respect to $d$
selected seeds: the probabilities from the $d$ corresponding seeds
randomly walking (diffusing) to the current vertex. Moreover, our
newly-devised DP can be immediately obtained from the existing QHF
without extra computational effort, at the same time it exhibits the
robustness of QHF. Therefore, DP can be considered as a powerful
measurement to classify vertices from the perspective of diffusion.

In the initial feature assignment, most types of vertices have already
been classified except planar vertices, we only need to handle planar vertices in this
step, and classify them into different patch features and curve
features via our classification algorithm
(Algorithm~\ref{classification}). The key idea is to cluster planar
vertices to the corresponding seeds that have the maximum DP.
Naturally, the boundary of each patch feature constructs a curve
feature that reflects geometric saliency and segments the patch.
Therefore, we treat boundaries of the patches as curve features in our
classification algorithm. Intuitively speaking, patch features are
weaved together by curve features.

\begin{algorithm}[t]
\SetLine
\For{i=1:n}{
find $[f_{ij},j]$=$\max_j(DP(v_i,j))$\;
\If{$v_i$ is a non-planar vertex or $f_{ij}<1/j+0.1$}{continue\;}
add the vertex $v_i$ to the $j$-th patch feature, and assign it the color value $j$\;
remove it from planar vertices $V_P$\;
}
\If{$V_P$ is empty}
{mark the common boundary vertices of patch features as curve features\;}
\caption{Diffusion-probability-based Feature Classification.}
\label{classification}
\end{algorithm}

\begin{figure}[t]
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{} @{}c@{} @{}c@{}}
\includegraphics[width=0.22\textwidth, keepaspectratio]{bunny_small_patch.eps} &
\includegraphics[width=0.235\textwidth, keepaspectratio]{bunny_small_patch_merging.eps} \\
\includegraphics[width=0.21\textwidth, keepaspectratio]{octo_small_patch.eps} &
\includegraphics[width=0.215\textwidth, keepaspectratio]{octo_small_patch_merging.eps} \\
Before merging           & After merging\\
\end{tabular}
\caption{Merging small patch features.
The top row: the small patch is merged into its nearby patch
features. The bottom row: the small patch is merged into the
transition feature.}
\label{fig:merge}
\end{center}
\end{figure}

Now, we shall introduce our seed selection mechanism. In order to
automatically select seeds, a proper metric is inevitable. Many
commonly-used metrics, such as geodesic distance and diffusion
distance, suffice for this purpose. Nevertheless, accurately
calculating these metrics on manifolds is time-consuming in
principle. Since the QHF is already computed in the earlier stage, it
makes a perfect sense to devise a distance metric that makes full use
of it. In the $d$-dimensional QHF $F$, we define a probability
distance between two vertices as
\begin{equation}
\label{eq:distance}
DP_F(v_i,v_j)= \| F_{i}-F_{j}\|_2.
\end{equation}
For a generic family of probability distribution functions (PDFs), it
is easy to verify that when $d>2$, the distance $DP_F(v_i,v_j)$ is a
metric by using Minkowski's inequality. This distance metric will be
further employed to merge small patch features in later stages.

\begin{algorithm}[t]
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetLine
\Input{Cholesky factorization of the coefficient matrix $\textbf{L}$,
planar vertices $V_P$.}
\Output{Classification result.}
Initialize: $C=\emptyset$, $\bar{C}=\emptyset$, $C_{d}=\emptyset$.\\
\While{$V_P$ is not empty}{
  1: set $C_{i}=\emptyset$, select a new seed from $V_P$ that has
the minimum sum of distances from the existing seeds,
and insert it to $C_{i}$ and $\bar{C}$.\\
  2: fast update the Cholesky via Eq.~(\ref{eq:Penalty_function}),
and obtain the updated $\textbf{F}$.\\
  3: classify the planar vertices using Algorithm~\ref{classification},
and set $C$=$\bar{C}$.\\
}
\caption{Feature classification with automatic seed selection.}
\label{automatically}
\end{algorithm}

We iteratively determine seeds based on this newly-proposed distance
measurement. During the iteration, a new seed is chosen with the
minimum distance value to all the existing seeds.
Fig.~\ref{fig:distance} illustrates an example of how a new seed can
be automatically placed on the model and where to place such seed in
an automatic way. The feature classification based on automatic seed
selection is documented in Algorithm~\ref{automatically}. Given the
Cholesky factorization of coefficient matrix and the non-classified
planar vertices, the classification is achieved after a fewer
iterations. Since the QHF has been computed in an earlier stage, the
distance measures and their summation can be obtained directly.
If the user needs to further segment
large patch features into small ones, our system also supports the
user interaction, which can be handle in a similar way. Note that, the
number of selected seeds equals to the number of patch features.

\begin{figure}[t]
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{} @{}c@{} @{}c@{}}
\includegraphics[width=0.25\textwidth, keepaspectratio]{fandisk_original.eps} &
\includegraphics[width=0.25\textwidth, keepaspectratio]{fandisk_multi_1.eps} \\
 Original mesh &  $c_f=0.03$, $\delta_D=0.20$\\
\includegraphics[width=0.25\textwidth, keepaspectratio]{fandisk_multi_2.eps}&
\includegraphics[width=0.25\textwidth, keepaspectratio]{fandisk_multi_3.eps}\\
$c_f=0.025$, $\delta_D=0.18$ & $c_f=0.025$, $\delta_D=0.16$\\
\end{tabular}
\caption{Multi-level feature classification on the Fandisk,
obtained by adjusting the curve feature parameter $c_f$
and the diffusion parameter $\delta_D$.}
\label{fig:multi-level}
\end{center}
\end{figure}

\begin{figure*}
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} }
\includegraphics[width=0.25\textwidth, keepaspectratio]{Octa-flower_noise.eps}&
\includegraphics[width=0.25\textwidth, keepaspectratio]{Octa-flower_cluster_noise.eps}&
\includegraphics[width=0.18\textwidth, keepaspectratio]{hand_noise.eps}&
\includegraphics[width=0.20\textwidth, keepaspectratio]{hand_cluster_noise.eps}\\
\includegraphics[width=0.25\textwidth, keepaspectratio]{Octa-flower_holes.eps} &
\includegraphics[width=0.25\textwidth, keepaspectratio]{Octa-flower_cluster_holes.eps}&
\includegraphics[width=0.18\textwidth, keepaspectratio]{hand_holes.eps} &
\includegraphics[width=0.18\textwidth, keepaspectratio]{hand_holes_cluster.eps}\\
\end{tabular}
\caption{Feature classification results for models with noise and holes.
The first row: models (Octa-flower and Hand) with $10\%$ random noise.
The second row: models with holes.}
\label{fig:noise}
\end{center}
\end{figure*}

\begin{figure*}
\begin{center}
\begin{tabular}{@{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{}}
\includegraphics[width=0.23\textwidth, keepaspectratio]{fandisk_original_.eps} &
\includegraphics[width=0.23\textwidth, keepaspectratio]{fandisk_rw_cluster.eps} &
\includegraphics[width=0.23\textwidth, keepaspectratio]{fandisk_tv_cluster.eps} &
\includegraphics[width=0.23\textwidth, keepaspectratio]{fandisk_our_cluster.eps}\\
\includegraphics[width=0.21\textwidth, keepaspectratio]{hand_2_o.eps} &
\includegraphics[width=0.21\textwidth, keepaspectratio]{hand_2_rw_cluster.eps} &
\includegraphics[width=0.21\textwidth, keepaspectratio]{hand_2_tv_cluster_.eps} &
\includegraphics[width=0.21\textwidth, keepaspectratio]{hand_2_our_cluster.eps}\\
(a)& (b)  &(c)  & (d) \\
\end{tabular}
\caption{Comparison of different methods.
(a) Original meshes. (b) The results of random walk~\cite{LHMR09}. (c)
The results of tensor voting~\cite{KCL09}. (d) Our results
($c_f=0.025$, $\delta_D=0.16$).}
\label{fig:comparison}
\end{center}
\end{figure*}

\subsection{Curve-tracking and Post-processing}
\label{sec:EP}

Now, the vertices are classified into different features. For models
with sharp edge features, we build a concise representation for a
curve feature by ordering the vertices and connecting them. This
representation is useful in downstream graphics applications. In
previous methods~\cite{OBS04,KDTD07}, the connection algorithms are
utilized, even though they may generate many branches and intricate
lines. In our work, this can be easily handled using the principal
diffusion directions. Smooth feature curves are found by
curve-tracking along the principal diffusion directions. For an edge
of $M$, if both endpoints belong to point features or curve features,
and at least one of the principal diffusion directions is close to the
edge (whose intersecting angle is less than $15^\circ$), the two
endpoints are connected to form a line segment contributing to a
feature curve. For more general models, different line features and
point features may be interleaved together to form a more complicated
transition region. In this case, these features are just illustrated
by color rather than clustering into a connected curve.

Finally, a post-processing step might still be needed to process small
patch features. A small patch feature is recognized as the one with
the number of vertices fewer than a given threshold (we set it to be
$0.1\%$ of the total number of vertices in this paper). It is possible
that a large feature is separated by small ones due to noise or
non-salient geometry. We tackle this problem by merging a small patch
into the most relevant neighboring patch (if such patch exists), whose
seed has the minimum distance to the small patch. The distance of a
vertex $v$ to a patch $P$ is defined as
\begin{equation}
\label{eq:distance_P}
DP_F(v,P)=\min_{u\in P}\{DP_F(v,u)\}.
\end{equation}
Sometimes, a small patch is surrounded by transition features. In this
case, we just merge it into a transition feature. Fig.~\ref{fig:merge}
shows the example of merging small patch features. Note that, this
post-processing stage is rather optional and can be skipped by users,
since small patches may be useful in certain applications.

\begin{figure*}
\centering
\begin{minipage}{0.22\textwidth}
\centering
\includegraphics[width=\textwidth]{tre_twist_clustering.eps}\\
\vspace{4pt}
\includegraphics[width=\textwidth]{tre_twist_features.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.12\textwidth}
\centering
\includegraphics[width=\textwidth]{mechnaical_clustering.eps}\\
\vspace{4pt}
\includegraphics[width=\textwidth]{mechnaical_features.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.22\textwidth}
\centering
\vspace{10pt}
\includegraphics[width=\textwidth]{sharp_sphere_clustering.eps}\\
\vspace{10pt}
\includegraphics[width=\textwidth]{sharp_sphere_features.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.24\textwidth}
\centering
\vspace{20pt}
\includegraphics[width=\textwidth]{cosine_plane_clustering.eps}\\
\vspace{20pt}
\includegraphics[width=0.95\textwidth]{cosine_plane_features.eps}\\
\end{minipage}\\ \vspace{4pt}
\hspace{0.02\textwidth} (a) Tre-twist  \hspace{0.09\textwidth} (b) Block   \hspace{0.09\textwidth} (c) Sharp sphere  \hspace{0.12\textwidth}(d) Cosine plane\\ \vspace{8pt}
\begin{minipage}{0.2\textwidth}
\centering
\vspace{20pt}
\includegraphics[width=\textwidth]{cup_cluster.eps}\\
\vspace{30pt}
\includegraphics[width=\textwidth]{cup_feature.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.3\textwidth}
\centering
\vspace{30pt}
\includegraphics[width=\textwidth]{teapot_clustering.eps}\\
\vspace{40pt}
\includegraphics[width=0.7\textwidth]{teapot_feature.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.13\textwidth}
\centering
\includegraphics[width=\textwidth]{pawn_clustering.eps}\\
\vspace{40pt}
\includegraphics[width=\textwidth]{pawn_feature.eps}\\
\end{minipage} \hspace{10pt}
\begin{minipage}{0.12\textwidth}
\centering
\includegraphics[width=0.9\textwidth]{canstick_clustering.eps}\\
\vspace{20pt}
\includegraphics[width=0.82\textwidth]{canstick_feature.eps}\\
\end{minipage}\\ \vspace{4pt}
\hspace{0.05\textwidth} (e) Cup  \hspace{0.19\textwidth} (f) Teapot  \hspace{0.16\textwidth}  (g) Pawn  \hspace{0.04\textwidth} (h) Canstick\\
    \caption{More examples for man-made objects.
    The connected curve features are highlighted beneath
    the feature classification results.}
    \label{fig:others}
\end{figure*}

%-------------------------------------------------------------------------

\section{Experimental Results and Discussions}
\label{sec:ERD}

\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
    \label{table:1}
    \caption{Time performance of updating quasi-harmonic fields with high dimensional seeds.}
    \centering
    \begin{tabular}{c||c |c |c|c}
    \hline Models            &\# $V$ & \# $C_{i}$     & \# $C_{d}$          & Time (sec) \\
    \hline\hline   Tre-twist &12800  & 10 &  10 & 0.001 \\
     \hline  Pawn &68000                     & 10                       &  10                     & 0.009 \\
    \hline   Pawn &68000                      & 1                        &  1                      & 0.001 \\
    \hline   hand &170000                     & 10                       &  1                      & 0.028 \\
    \hline   hand &170000                     & 1                        &  0                      & 0.002 \\
    \hline
    \end{tabular}
\end{table}

\begin{figure*}[t]
\begin{center}
    \begin{tabular}{@{}c@{} @{}c@{} @{}c@{}}
       \includegraphics[width=0.26\textwidth, keepaspectratio]{bunny.eps}&
        \includegraphics[width=0.43\textwidth, keepaspectratio]{octo.eps}\\
         (a) Bunny & (b) Octopus \\
        \includegraphics[width=0.35\textwidth, keepaspectratio]{lion.eps}&
       \includegraphics[width=0.56\textwidth, keepaspectratio]{eagle.eps}\\
 (c) Lion & (d) Eagle\\
    \end{tabular}
    \caption{Feature classification on organic models.
    Patch features are shown in different colors,
    while all other features, including point features,
    curve features and transition features are shown in red.}
    \label{fig:general}
\end{center}
\end{figure*}

In this section, we demonstrate the performance of our method by
conducting experiments in various aspects, including multi-level
classification, noisy meshes, comparison with other methods, general
models, and deformable meshes. All the experiments documented in this
paper are conducted on a computer with 1.6GHz Intel Core (TM,
4Core/8Threads) i7 CPU with 4G RAM, where both synthetic and scanned
meshes are utilized. Most computation expenses of our approach can be
done in the pre-processing stage, such as the diffusion tensor
computation, feature initialization, and Cholesky decomposition of the
coefficient matrix. Since only the updating procedure instead of
re-computation is needed in each iteration, our method is extremely
efficient and can reach real-time performance. Table 1 summarizes the
statistics and timing performance of fast updating of the QHF for a
collection of datasets used in our experiments, where $\#C_{i}$ and
$\#C_{d}$ are the numbers of newly-inserted seeds and deleted seeds,
respectively.

\textbf{Parameters and Multi-level Classification.}
Parameter selection is a challenge for versatile intelligent methods.
Usually, fewer parameters and flexible multi-functional capabilities
are conflicting with each other, people have to find a good tradeoff
in practice. There are also a few parameters in our approach, however,
most of them are either self-adaptive or determined empirically, and
they are consistent throughout different models. We only need to pay
special attention to two parameters: curve feature parameter $c_f$ and
the diffusion parameter $\delta_D$. As we discussed above, $c_f$
influences curve features, and $\delta_D$ controls the influence of
diffusion tensor to the QHF. They are set to be 0.03 and 0.16
respectively by default if there is no special explanation.

Our method also supports hierarchical feature classification by
interactively adjusting the curve feature parameter and the diffusion
parameter to form different combinations. From coarse to fine, a large
piece of patch feature may be further classified into some small
pieces. Fig.~\ref{fig:multi-level} shows the multi-level results of
the Fandisk with different parameters. We want to particularly mention
that the curve feature parameter is intuitive, users can interactively
slide the value bar to obtain the desired curve features. In our
ongoing work, we would like to improve the parameter setting by
exploring the intrinsic relationship between the curve feature
parameter and the diffusion parameter, and devise a semi-adaptive
parameter selection scheme.

\textbf{Classification on Meshes with Noise and Holes.}
The tensor is a local attribute determined by a small neighborhood of
a vertex. Therefore, only using the local tensor~\cite{KCL09} can be
easily affected by noise. To address this problem, we adopt QHFs in
our method to classify features, which are stable solutions to heat
diffusion. The QHFs have high resilience in combating noise and holes.
Moreover, the gap between features and noise are further magnified by
exploiting the information of the diffusion tensor.
Fig.~\ref{fig:illustrate} and Fig.~\ref{fig:noise} show the
classification results under noise and holes. We add $10\%$ (of
average edge length) random noise to perturb vertex coordinates, and
punch some holes (topological noise) on the models. The small holes
almost have no negative effect on the results because of the diffusion
nature. When a hole is too large to allow the diffusion to pass
through by traversing around the hole boundary, the corresponding
patches will be further classified into smaller patches according to
the hole locations (Fig.~\ref{fig:noise}(bottom left)). Note that, due
to the diffusion nature of our QHF, no special processing is required
for the holes and open boundaries.

%%%
%%% what does it mean: large or partial lose???
%%% I remove the Partial lose, only mention large holes.
%%% I also add the note of holes and open boundaries.

\begin{table}
\renewcommand{\arraystretch}{1.3}
\label{table:2}
\caption{Comparison of different methods in time (sec).}
\centering
\begin{tabular}{c||c|c|c|c}
\hline          Models    & \# V             & RW               & TV                 & Ours \\
\hline\hline  Fandisk     &  6477             & 0.44                  & 3.54               & 0.15 \\
\hline  Tre-twist          &12800          & 1.78                  & 5.13               & 0.29 \\
\hline  Pawn              &68000               & 8.64                  & 24.16              & 1.24 \\
\hline  Octopus            &100000          & 12.05                 & 34.47             & 2.58 \\
\hline  Hand               &170000          & 30.13                 & 70.52              & 5.36\\
\hline
\end{tabular}
\end{table}

\begin{figure*}
\begin{center}
    \begin{tabular}{@{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{} @{}c@{}}
           \includegraphics[width=0.24\textwidth, keepaspectratio]{hand_deform_1.eps}&
           \includegraphics[width=0.21\textwidth, keepaspectratio]{hand_deform_2.eps}&
        \includegraphics[width=0.21\textwidth, keepaspectratio]{hand_deform_3.eps}\\
       \includegraphics[width=0.36\textwidth, keepaspectratio]{octo_deform_1.eps}&
        \includegraphics[width=0.34\textwidth, keepaspectratio]{octo_deform_2.eps}&
        \includegraphics[width=0.25\textwidth, keepaspectratio]{octo_deform_3.eps}\\
    \end{tabular}
    \caption{Consistent classification of deformed models.
The classified features are well preserved under a series of
near-isometric deformations.}
    \label{fig:Deformed}
\end{center}
\end{figure*}

\textbf{Comparison and Discussion.}
In Fig.~\ref{fig:comparison}, we compare our method with previous
related methods: random walk (RW)~\cite{LHMR09} (b), and tensor voting
(TV)~\cite{KCL09} (c). The RW method fails to find weak features,
since there is no feasible criterion to stop the random walk from
passing through the weak features. Moreover, since the matrix of
random walk is not symmetric, fast Cholesky factorization is not
applicable, which limits its computational speed. The TV method can
not distinguish weak features from noise either. Therefore, the
clustering is sensitive to noise, and much more post-processing is
unavoidable. Besides, neither could distinguish different patch
features, they instead consider them collectively as one patch. Our
method can classify the vertices into different features, and it can
detect both the weak features and the smooth transition features for
noisy meshes (Fig.~\ref{fig:illustrate} and
Fig.~\ref{fig:comparison}(d)). Table 2 summarizes the running time of
the algorithms used in experiments in Fig.~\ref{fig:comparison}. Note
that, all the time listed does not include the pre-processing. It
indicates that our method performs better than the other methods in
terms of both speed and classification results.

\textbf{More Examples including Deformed Models.}
More experimental results are shown to further demonstrate the
performance of our method. Fig.~\ref{fig:others} demonstrates some
results of rigid manufactured objects. The connected curve features
are highlighted beneath the classification results. We also examine
our method on natural objects, with experiments in
Fig.~\ref{fig:general}. For simplicity, different patch features are
shown in different colors, and all other types of features, including
point features, curve features and transition features are shown in
red. Near-isometric deformation usually preserves significant features
of models.  Thus, our method can be expected to generate consistent
results under this deformation.  Fig.~\ref{fig:Deformed} shows the
classification of three deformed models.  Most classification results
are well preserved undergoing deformation, except for some places
where the geometric features vanish after deformation, such as some
creases on the thumb.

\textbf{Limitations.}
Certain limitations of our method still exist, which call for further
improvement. Since the curve features of general models are often
complicated, they can not be easily represented by wire-frames as
rigid models do. For the clarity of visualization, we just highlight
them by red color in this paper. How to give a more general
representation, that considers semantics and is more
application-oriented, will be our future work.

%-------------------------------------------------------------------------
\section{Conclusion and Future Work}
\label{sec:CFW}

In this paper, we have articulated a new method for feature extraction
and classification on meshes, based on diffusion tensor driven
quasi-harmonic fields. A diffusion tensor has been locally designed to
collectively control the global anisotropic behavior of heat
diffusion. Such diffusion tensor has also been utilized to eliminate
noise and form feature curves.  The novelty of our method centers at
the elegant integration of the locally-defined diffusion tensor and
the globally-defined quasi-harmonic field in an anisotropic
manner. Moreover, we transform the non-linear diffusion problem into a
linear problem of field construction to make our method
computationally efficient.  A greedy feature classification process
enables our method to handle both rigid manufactured parts and organic
deformable objects. We believe that the fundamental ideas in this
paper can propel us to pursue more real-world applications, including
feature-driven shape registration, local feature-sensitive
parameterization, object recognition, shape synthesis, etc.

For immediate future work, we are planning to extend our method to
handle diverse types of geometric and scientific data, such as point
clouds in urban architecture modeling, volumetric data in medical
imaging, and higher dimensional manifolds in scientific
disciplines. Moreover, applying this approach to vector/tensor field
design, texture synthesis, and feature-aware non-photorealistic
visualization deserves further investigation which could significantly
broaden our method's application scopes.

%-------------------------------------------------------------------------

% use section* for acknowledgement
\ifCLASSOPTIONcompsoc
  % The Computer Society usually uses the plural form
  \section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgment}
\fi

This research is supported in part by the Fundamental Research Fund
for the Central Universities, National Natural Science Foundation of
China-Guangdong Joint Fund grant U0935004, National Natural Science
Foundation of China grants 60873181 and 61173103, and US National
Science Foundation grants IIS-0710819, IIS-0949467, IIS-1047715, and
IIS-1049448. Some of models are courtesy of the AIM@SHAPE repository.


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliographystyle{IEEEtran}
\bibliography{tvcg}
%\begin{IEEEbiography}{Shengfa Wang}
%%Biography text here.
%%%is a joint Ph.D. candidate of School of Mathematical Sciences at Dalian
%%%University of Technology and the Department of Computer Science at Stony Brook
%%%University (SUNY). He received his B.S. degree in Department of Information and
%%%Computing Science from Dalian University of Technology in 2007. His research
%%%interests include computer graphics, geometric modeling and differential geometry
%%%processing and analysis.
%\end{IEEEbiography}
%%
%\begin{IEEEbiography}{Tingbo Hou}
%%Biography text here.
%%%is a Ph.D. candidate in Department of Computer Science, Stony Brook
%%%University (SUNY). He received his B.S. degree from University of Science and Technology of China in 2004, and his M.E. degree from Chinese Academy of Sciences in 2007. His research interests include visual computing, shape analysis, shape matching/registration, geometric modeling, computer vision, and image processing.
%\end{IEEEbiography}
%%
%\begin{IEEEbiography}{Shuai Li}
%%Biography text here.
%%%is a postdoctorate researcher at School of Biological Science and Medical
%%%Engineering of Beihang University. He got his Phd from Computer Science School
%%%of Beihang University (China) in 2010. His research interest includes computer
%%%graphics, realtime and realistic rendering, medical image processing, physics
%%%based modeling and simulating, etc.
%\end{IEEEbiography}
%%
%\begin{IEEEbiography}{Zhixun Su}
%%Biography text here.
%%%is a professor in School of Mathematical Sciences and the Director of
%%%Key Lab of Computational Geometry, Graphics and Images at Dalian University of
%%%Technology. He got his B.S. in Mathematics at Jilin University, M.S. in Computer
%%%Science at Nankai University and Ph. D. in Computational Mathematics at Dalian
%%%University of Technology. His research interests are on computational geometry,
%%%computer graphics, image processing, and computer vision. He is now an executive
%%%member of China Society for Computational Mathematics.
%\end{IEEEbiography}
%%
%\begin{IEEEbiography}{Hong Qin}
%%Biography text here.
%%%is a professor of Computer Science in Department of Computer Science
%%%at State University of New York at Stony Brook (Stony Brook
%%%University). He received his B.S. degree and his M.S. degree in
%%%Computer Science from Peking University, China. He received his
%%%Ph.D. (1995) degree in Computer Science from the University of
%%%Toronto. During his years at the University of Toronto (UofT), he
%%%received UofT Open Doctoral Fellowship. He was also a recipient of NSF
%%%CAREER Award from the National Science Foundation (NSF), Honda
%%%Initiation Award, and Alfred P. Sloan Research Fellow by the Sloan
%%%Foundation. Currently, he serves as an associate editor for The Visual
%%%Computer, Graphical Models, and Journal of Computer Science and
%%%Technology. His research interests include geometric and solid
%%%modeling, graphics, physics-based modeling and simulation, computer
%%%aided geometric design, human-computer interaction, visualization, and
%%%scientific computing. Detailed information about Dr. Hong Qin can be
%%%found from his website: \url{http://www.cs.sunysb.edu/~qin}. He can be
%%%reached at qin@cs.sunysb.edu.
%\end{IEEEbiography}


% that's all folks
\end{document}


%%% we will leave the biography section out for this round of review process!!!

% biography section



%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in} 